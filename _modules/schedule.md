---
title: Paper reading list and presenters
---

Jan 27, Thu
: [Course Overview](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=5f6867f8-01c6-4128-a8c4-ae2a0143b145) ([slides](https://drive.google.com/file/d/1N9kidliGRNPrfeERrUwlozbUbMoFg1l3/view?usp=sharing))
  : Chen Sun

Feb. 1, Tue
: [Recap: CNNs and Transformers](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=aae5ae83-07b9-4f22-a060-ae2f01471dc6) ([slides](https://drive.google.com/file/d/1DjQUQGoE1pRn0t5BtTTeVIwmy1jG-lys/view?usp=sharing))
  : Chen Sun
: 1. [Presentation signup sheet](https://forms.gle/DH4uV5JcJK5BjoFw8)
  1. [Paper nomination form](https://forms.gle/keevGHpxqbgCK1QQ7)

Feb. 3, Thu
: [Overview: Self- and Cross-modal Learning](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=ea14d639-88aa-42cb-a20d-ae310144e06e) ([slides](https://drive.google.com/file/d/1WsuVg-HjmxEhUmGOi1Y1Q3eVi44YPrIm/view?usp=sharing))
  : Chen Sun
: 1. (Background) [How to Read a CS Research Paper](http://www2.cs.uregina.ca/~pwlfong/CS499/reading-paper.pdf) by Philip Fong
  1. (Background) [How to do research](http://people.csail.mit.edu/billf/publications/How_To_Do_Research.pdf) by Bill Freeman
  1. (Background) [How to do write a good paper](https://billf.mit.edu/sites/default/files/documents/cvprPapers.pdf) by Bill Freeman
  1. (Background) [Novelty in Science](https://perceiving-systems.blog/en/news/novelty-in-science) by Michael Black
  1. (Background) [Self-supervised learning: The dark matter of intelligence](https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/) by Yann LeCun and Ishan Misra

Feb. 4, Fri
: **Due**{: .label .label-purple} [Presentation signup](https://forms.gle/DH4uV5JcJK5BjoFw8)

Feb. 8, Tue
: [The Unreasonable Effectiveness of Data](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=035c0c2b-c071-45ed-bd2f-ae3601458e1b) ([Reading survey](https://docs.google.com/forms/d/e/1FAIpQLSfTwd-6uZ7NzQiV8Q7QHCGp4xjOYqO7Mn7PuFiEOgySI6n_Fw/viewform?usp=sf_link) / [Questions](https://drive.google.com/file/d/1nM-7HR8NCwb09mM_EJ6uZT1c-niIIJS5/view?usp=sharing) / [Slides](https://docs.google.com/presentation/d/1UMCutUbumhAz9uiE1YTVuqlD4EOuUFa55EJatpoWG4k/edit?usp=sharing))
  : Jorge, Koyena, Yipu
: 1. [Revisiting Unreasonable Effectiveness of Data in the Deep Learning Era](https://arxiv.org/abs/1707.02968)
  1. [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)
  1. (Background) [The Unreasonable Effectiveness of Data](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf)
  1. (Background) [Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877)
  1. (Background) [Exploring Randomly Wired Neural Networks for Image Recognition](https://arxiv.org/abs/1904.01569)
  1. (Background) [NAS evaluation is frustratingly hard](https://arxiv.org/abs/1912.12522)
  1. (Background) [The bitter lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)


Feb. 10, Thu
: [Semi-supervised Learning](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=9ecb9780-2648-4720-8dc0-ae38014aacf7) ([Reading survey](https://forms.gle/m3FywjTPnR8gPQRw8) / [Questions](https://drive.google.com/file/d/1YKwKzIK_0Awi2rcQFYewrAs4APUdLMm3/view?usp=sharing) / [Slides](https://drive.google.com/file/d/1FwAoyl-jF92EQxYQpH8B2b5aoBCscV8H/view?usp=sharing))
  : Cheng-You, Vivek
: 1. [Mean teachers are better role models](https://arxiv.org/abs/1703.01780)
  1. [MixMatch: A Holistic Approach to Semi-Supervised Learning](https://arxiv.org/abs/1905.02249)
  1. (Background) [Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907)
  1. (Background) [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216)
  1. (Background) [Transfer Learning in a Transductive Setting](https://papers.nips.cc/paper/2013/hash/3295c76acbf4caaed33c36b1b5fc2cb1-Abstract.html)

Feb. 15, Tue
: [Transfer Learning](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=a62479b4-0463-4499-a18a-ae3d014ff7ac) ([Reading survey](https://forms.gle/gLzydCU4LeX8ne419) / [Questions](https://drive.google.com/file/d/1_ZIEhkB3BU4KCoi9Hx-uRfZO1mjbirtA/view?usp=sharing) / [Slides](https://drive.google.com/file/d/1BF2QDw8Go6gDFrbPIpafxNQ-gz-5iGJX/view?usp=sharing))
  : Changcheng, Gabriel, Kangping
: 1. [Big Transfer (BiT): General Visual Representation Learning](https://arxiv.org/abs/1912.11370)
  1. [Rethinking Pre-training and Self-training](https://arxiv.org/abs/2006.06882)
  1. (Background) [A Survey on Transfer Learning](https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf)
  1. (Background) [Transfusion: Understanding Transfer Learning for Medical Imaging](https://arxiv.org/abs/1902.07208)
  1. (Background) [Learning and Transferring Mid-Level Image Representations using Convolutional Neural Networks](https://leon.bottou.org/publications/pdf/cvpr-2014.pdf)
  1. (Background) [A Large-scale Study of Representation Learning with the Visual Task Adaptation Benchmark](https://arxiv.org/abs/1910.04867)
  1. (Background) [Rethinking ImageNet Pre-training](https://arxiv.org/abs/1811.08883)

Feb. 17, Thu
: [Few-shot Learning](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=952e445b-a677-4a00-b7f9-ae3f014708f5) ([Reading survey](https://forms.gle/75nD6SggbifS9ER89) / [Questions](https://drive.google.com/file/d/1QdyKtq04_rv5m9DTFnpO5-8rIEI7mE1Y/view?usp=sharing) / [Slides](https://docs.google.com/presentation/d/1YkQ1zvLOQY8Ke9ydDkiQ2okA7GsBiZ1tA6hHksY4aRM/edit?usp=sharing))
  : Anessa, Reza, Yong
: 1. [Matching Networks for One Shot Learning](https://arxiv.org/abs/1606.04080)
  1. [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://arxiv.org/abs/1703.03400)
  1. (Background) [Prototypical Networks for Few-shot Learning](https://arxiv.org/abs/1703.05175)
  1. (Background) [Learning to Learn (Blog)](https://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/)
  1. (Background) [Meta-Learning: Learning to Learn Fast (Blog)](https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html)
  1. (Background) [A Closer Look at Few-shot Classification](https://arxiv.org/abs/1904.04232)
  1. (Background) [Rethinking Few-Shot Image Classification: a Good Embedding Is All You Need?](https://arxiv.org/abs/2003.11539)

Feb. 22, Tue
: _University holiday, no class_

Feb. 24, Thu
: [Multitask Learning](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=c8f091b2-f57a-447f-9451-ae4601429895) ([Reading survey](https://forms.gle/fdPWVFNMASZpMJY98) / [Questions](https://drive.google.com/file/d/1RP6cshnmuhvMlvlTmT4EpbvOHHeGaVxe/view?usp=sharing) / [Slides](https://docs.google.com/presentation/d/1HIeTUBYc5aKPAGn55szw7Jrw-tlUWzlEC4yVG7Yp3Ps/edit?usp=sharing))
  : Amir, Hyuk, Jinwoo, Leonard
: 1. [Taskonomy: Disentangling Task Transfer Learning](https://arxiv.org/abs/1804.08328)
  1. [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) (Section 1, 2, 4)
  1. (Background) [UberNet: Training a Universal Convolutional Neural Network](https://arxiv.org/abs/1609.02132)
  1. (Background) [On the Opportunities and Risks of Foundation Models](https://arxiv.org/abs/2108.07258)
  1. (Background) [ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning](https://arxiv.org/abs/2111.10952)

Mar. 1, Tue
: [AI Safety](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=823e5097-b02f-4563-869a-ae4b01463457) ([Reading Survey](https://forms.gle/QoJUBqmJCz5BAUF86) / [Questions](https://drive.google.com/file/d/1ACY2VKSi0dIgt8QK0d_ksZAhEGu-zEWP/view?usp=sharing) / [Slides](https://docs.google.com/presentation/d/1lGvMzBny74PIUaIHi3vTuKC-mLGqdr0EJW4zlZTspp8/edit?usp=sharing))
  : Anna, Mason, Will Yang 
: 1. [Concrete Problems in AI Safety](https://arxiv.org/abs/1606.06565)
  1. (Background) [Deep reinforcement learning from human preferences](https://arxiv.org/abs/1706.03741)
  1. (Background) [AI safety via debate](https://arxiv.org/abs/1805.00899)
  1. (Background) [Avoiding Side Effects By Considering Future Tasks](https://arxiv.org/abs/2010.07877)
  1. (Background) [Objective Robustness in Deep Reinforcement Learning](https://arxiv.org/abs/2105.14111)
  
Mar. 3, Thu
: [Transformer and its variants](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=707347b7-072c-475d-9ff9-ae4d015157ba) ([Reading Survey](https://forms.gle/PDixJJZp9qz9DLnY7) / [Questions](https://drive.google.com/file/d/1WYMEMfRm9NFLD5JLZBz4VoXFCLFoLlPW/view?usp=sharing) / [Slides1](https://docs.google.com/presentation/d/11JJBJ-KYX6EQubnk5LgwCPAntUoMe3NQ/edit?usp=sharing&ouid=107174457905760692415&rtpof=true&sd=true) / [2](https://docs.google.com/presentation/d/1oY7WZgx456OzR0wEc0-8Ubl7WdfZFqXd/edit?usp=sharing&ouid=107174457905760692415&rtpof=true&sd=true))
  : George Zerveas, Kai
: 1. [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062)
  1. [Synthesizer: Rethinking Self-Attention in Transformer Models](https://arxiv.org/abs/2005.00743)
  1. (Background) [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/abs/2101.03961)
  1. (Background) [MLP-Mixer: An all-MLP Architecture for Vision](https://arxiv.org/abs/2105.01601)
  1. (Background) [Linformer: Self-Attention with Linear Complexity](https://arxiv.org/abs/2006.04768)
  1. (Background) [Highly accurate protein structure prediction with AlphaFold](https://www.nature.com/articles/s41586-021-03819-2)

Mar. 8, Tue
: [Vision Transformers (1)](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=9d3aebc4-6af3-42cb-aba2-ae520145323b) ([Reading Survey](https://forms.gle/VNs1ci5va9TyCUkB6) / [Questions](https://drive.google.com/file/d/11Lh4DGXfYPt_kMXIB9KlZx44vpIINe8t/view?usp=sharing) / [Slides](https://docs.google.com/presentation/d/1zLEjfVcC_WqR-j88ZshWA5jb5kzb9B-mFFi0QYcDqa8/edit?usp=sharing))
  : Chace, Justin, Shijie
: 1. [Swin Transformer](https://arxiv.org/abs/2103.14030)
  1. [On the Relationship between Self-Attention and Convolutional Layers](https://arxiv.org/abs/1911.03584)  
  1. (Background) [ViViT: A Video Vision Transformer](https://arxiv.org/abs/2103.15691)
  1. (Background) [VideoBERT: A Joint Model for Video and Language Representation Learning](https://arxiv.org/abs/1904.01766)
  1. (Background) [Video Action Transformer Network](https://arxiv.org/abs/1812.02707)

Mar. 10, Thu
: [Vision Transformers (2)](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=aec644c6-e666-4019-a373-ae540144df28) ([Reading Survey](https://forms.gle/p9QyGLAXwQgDy4FHA) / [Questions](https://drive.google.com/file/d/1TF_PyNX44ln1287Nid4XrXZv_0yljarb/view?usp=sharing) / [Slides](https://docs.google.com/presentation/d/1WusDD484Vf-GLefxERdTIwFyjUTc256tc9KaWU5r59o/edit?usp=sharing))
  : Avi, George Hu, Peilin
: 1. [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)
  1. [Perceiver: General Perception with Iterative Attention](https://arxiv.org/abs/2103.03206)
  1. (Background) [TrackFormer: Multi-Object Tracking with Transformers](https://arxiv.org/abs/2101.02702)
  1. (Background) [MaX-DeepLab: End-to-End Panoptic Segmentation With Mask Transformers](https://arxiv.org/abs/2012.00759)
  1. (Background) [Perceiver IO: A General Architecture for Structured Inputs & Outputs](https://arxiv.org/abs/2107.14795)
  1. (Background) [Episodic Transformer for Vision-and-Language Navigation](https://arxiv.org/abs/2105.06453)

Mar. 11, Fri
: **Due**{: .label .label-purple} [Final project signup](https://forms.gle/CgoE6bgbGKTm1YBi6)

Mar. 14, Mon
: **Due**{: .label .label-purple} [Mid-term feedback](https://forms.gle/nmryhxNb8JmdJ9Cc9)

Mar. 15, Tue
: [Self-supervised Learning for NLP](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=ae258fd6-7c11-429e-9f0b-ae5901358c60) ([Reading Survey](https://forms.gle/MfWCZ3jFphqVHrVB8) / [Questions](https://drive.google.com/file/d/1Uj2GFvnOd6rxLZ_5pxcFJHg5IphXPdNX/view?usp=sharing) / [Slides](https://docs.google.com/presentation/d/17j4SlS7oaKbwAgGQsaPQTBTrA09ylJOEoFTce8dj2XA/edit?usp=sharing))
  : Catherine, William Jurayj, William Rudman
: 1. [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)
  1. [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?](https://dl.acm.org/doi/10.1145/3442188.3445922)
  1. (Background) [REALM: Retrieval-Augmented Language Model Pre-Training](https://arxiv.org/abs/2002.08909)
  1. (Background) [SpanBERT: Improving Pre-training by Representing and Predicting Spans](https://arxiv.org/abs/1907.10529)
  1. (Background) [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)
  1. (Background) [Human Language Understanding & Reasoning](https://www.amacad.org/publication/human-language-understanding-reasoning)
  1. (Background) [Do Large Language Models Understand Us?](https://www.amacad.org/publication/do-large-language-models-understand-us)

Mar. 17, Thu
: [Self-supervised Learning for Images](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=11d159b5-a930-4db8-ada5-ae5b0133ae03) ([Reading Survey](https://forms.gle/Y4pyXenM7crXj6zp6) / [Questions](https://drive.google.com/file/d/1nqO6j5TW2rQVWdRy20Wup-1NDAcL0hI_/view?usp=sharing) / [Slides](https://docs.google.com/presentation/d/16Q0LaKPI4z4ziyRwtkXinUigrNPmOwOPdpGH3f83d5s/edit?usp=sharing))
  : Sijie, Tian, Vadim
: 1. [BEiT: BERT Pre-Training of Image Transformers](https://arxiv.org/abs/2106.08254)
  1. [Representation Learning with Contrastive Predictive Coding](https://arxiv.org/abs/1807.03748)
  1. (Background) [Dimensionality Reduction by Learning an Invariant Mapping](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf)
  1. (Background) [Vision Models Are More Robust And Fair When Pretrained On Uncurated Images Without Supervision](https://arxiv.org/abs/2202.08360)
  1. (Background) [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377)
  1. (Background) [Deep Clustering for Unsupervised Learning of Visual Features](https://arxiv.org/abs/1807.05520)
  1. (Background) [Towards the Generalization of Contrastive Self-Supervised Learning](https://arxiv.org/abs/2111.00743)
  1. (Background) [Bootstrap your own latent: A new approach to self-supervised Learning](https://arxiv.org/abs/2006.07733)

Mar. 22, Tue
: **Invited**{: .label .label-purple} [Learning Structured Models of the World](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=2c2fb7e3-d63b-4060-8283-ae6001347ede#)
  : [Thomas Kipf](https://tkipf.github.io/)
: 1. (Background) [Object-Centric Learning with Slot Attention](https://arxiv.org/abs/2006.15055)
  1. (Background) [Conditional Object-Centric Learning from Video](https://slot-attention-video.github.io/)

Mar. 24, Thu
: [Project proposal](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=be886c1a-e49a-4081-bd2c-ae6201322d41) ([Master deck](https://docs.google.com/presentation/d/15dgxZGzOuxGxafz73DtDIbgi-t526LO4jhhkm9qx8DE/edit?usp=sharing))

Mar. 29, Tue
: _Spring break_

Mar. 31, Thu
: _Spring break_

Apr. 5, Tue
: [Self-supervised Learning for Videos](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=16ff9a87-dd01-4b09-86bd-ae6e01302f4e) ([Reading Survey](https://forms.gle/mmtRy1EryGTWAiW9A) / [Slides](https://docs.google.com/presentation/d/1pRzY1lBZ_EePhs-jDFGVSFLUfoRrdBPtXVj9CJ2RaYc/edit#slide=id.g1215cebbd4f_73_0))
  : Bader, Ce, Trevor
: 1. [Time-Contrastive Networks: Self-Supervised Learning from Video](https://arxiv.org/abs/1704.06888)
  1. [Learning image representations tied to ego-motion](https://arxiv.org/abs/1505.02206)
  1. (Background) [Simulation as an engine of physical scene understanding](https://www.pnas.org/content/110/45/18327.short)
  1. (Background) [Learning correspondence from the cycle-consistency of time](https://arxiv.org/abs/1903.07593)
  1. (Background) [Learning Temporal Dynamics from Cycles in Narrated Video](https://arxiv.org/abs/2101.02337)

Apr. 7, Thu
: [Representation Learning for RL](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=720268f8-11d4-4d5a-81aa-ae700136f619) ([Reading Survey](https://forms.gle/adyasAPMPLw68tt77) / [Slides](https://docs.google.com/presentation/d/1T7hjs9JahBSTp3Ffo_aHoLoH0PDsiYxw2MngWvHce8w/edit?usp=sharing))
  : Aditya, Calvin, Haotian
: 1. [CURL: Contrastive Unsupervised Representations for Reinforcement Learning](https://arxiv.org/abs/2004.04136)
  1. [Decision Transformer: Reinforcement Learning via Sequence Modeling](https://arxiv.org/abs/2106.01345)
  1. (Background) [R3M: A Universal Visual Representation for Robot Manipulation](https://arxiv.org/abs/2203.12601)
  1. (Background) [Understanding the World Through Action](https://arxiv.org/abs/2110.12543)
  1. (Background) [Learning Latent Plans from Play](https://arxiv.org/abs/1903.01973)
  1. (Background) [Learning Latent Dynamics for Planning from Pixels](https://arxiv.org/abs/1811.04551)
  1. (Background) [Control-Aware Representations for Model-based Reinforcement Learning](https://arxiv.org/abs/2006.13408)
  1. (Background) [Shaping Belief States with Generative Environment Models for RL](https://arxiv.org/abs/1906.09237)
  1. (Background) [Goal-Aware Prediction: Learning to Model What Matters](https://arxiv.org/abs/2007.07170)

Apr. 8, Fri
: **Due**{: .label .label-purple} [Project proposal](https://forms.gle/yP8nx47cbjHnDDWu7)

Apr. 12, Tue
: **Invited**{: .label .label-purple} [Multimodal Learning](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=88f2bd3d-f645-476c-8164-ae75012db175) ([Slides](https://drive.google.com/file/d/12qvTeq_m3CIJ1tPtkLQnPQ0qoxINsATc/view?usp=sharing))
  : [Arsha Nagrani](https://a-nagrani.github.io/)
: 1. (Background) [Attention Bottlenecks for Multimodal Fusion](https://arxiv.org/abs/2107.00135)
  1. (Background) [Speech2Action: Cross-modal Supervision for Action Recognition](https://arxiv.org/abs/2003.13594)

Apr. 14, Thu
: [3D Computer Vision](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=d711ec2f-5d7c-4875-9a1c-ae7701345ed2) ([Reading Survey](https://forms.gle/Q8nF2vVcHNrZUXye8) / [Slides](https://docs.google.com/presentation/d/18VymGCbdY04yHbPgFPyJOMNEgTJngvjpfU7V4JhBGTE/edit?usp=sharing))
  : Arman, Jiahao, Mikhail, Rao
: 1. [MarrNet: 3D Shape Reconstruction via 2.5D Sketches](https://arxiv.org/abs/1711.03129)
  1. [NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://arxiv.org/abs/2003.08934)
  1. (Background) [Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges](https://arxiv.org/abs/2104.13478)
  1. (Background) [Instant Neural Graphics Primitives with a Multiresolution Hash Encoding](https://arxiv.org/abs/2201.05989)
  1. (Background) [PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593)

Apr. 19, Tue
: [Generative Modeling](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=c828ef6b-dd28-4bfa-90df-ae7c01333a72) ([Reading Survey](https://forms.gle/5yCtw9mKDcx7xDMg8) / [Slides](https://docs.google.com/presentation/d/1QHw3zT-jqB2lGj_5Xv2ecMnwMF14sL8j1R6ojOYgxVI/edit?usp=sharing))
  : Michal, Nate, Yuanhao
: 1. [Neural Discrete Representation Learning](https://arxiv.org/abs/1711.00937)
  1. [Diffusion Models Beat GANs on Image Synthesis](https://arxiv.org/abs/2105.05233)
  1. (Background) [PointFlow : 3D Point Cloud Generation with Continuous Normalizing Flows](https://www.cs.cornell.edu/~xhuang/publication/pointflow/)
  1. (Background) [Variational Graph Auto-Encoders](https://arxiv.org/abs/1611.07308)
  1. (Background) [What are Diffusion Models?](https://lilianweng.github.io/lil-log/2021/07/11/diffusion-models.html)
  1. (Background) [Zero-Shot Text-to-Image Generation](https://arxiv.org/abs/2102.12092)
  1. (Background) [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)

Apr. 21, Thu
: [Data and model bias](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=a1550b8b-75e7-46b1-818b-ae7e01351285) ([Reading Survey](https://forms.gle/4jcWyg73MQWQxQcm6) / [Slides](https://docs.google.com/presentation/d/1-sI3118c80XN5LVFeH-LOi_kaHz27Y9gfRbgJUtpI28/edit?usp=sharing))
  : Arun, Ghulam, Kunal, Pinar
: 1. [Beyond Accuracy: Behavioral Testing of NLP models with CheckList](https://arxiv.org/abs/2005.04118)
  1. [Equality of Opportunity in Supervised Learning](https://arxiv.org/abs/1610.02413)
  1. (Background) [Measuring and Reducing Gendered Correlations in Pre-trained Models](https://arxiv.org/pdf/2010.06032.pdf)
  1. (Background) [Comparing Human and Machine Bias in Face Recognition](https://arxiv.org/pdf/2110.08396.pdf)

Apr. 26, Tue
: [Model interpretability](https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=bd54e609-1894-42ee-ba72-ae8301412306) ([Reading Survey](https://forms.gle/9iEyoqhca4vg51AJA) / [Slides](https://docs.google.com/presentation/d/1v4LBBZSNBx-S4-RfC1vfkdLMtQR1ctdltZEa-gRDYf8/edit?usp=sharing))
  : Amanda, Usha, Zachary
: 1. [Do Vision Transformers See Like Convolutional Neural Networks?](https://arxiv.org/abs/2108.08810)
  1. [Acquisition of Chess Knowledge in AlphaZero](https://arxiv.org/abs/2111.09259)
  1. (Background) [BERT rediscovers the classical NLP pipeline](https://arxiv.org/abs/1905.05950)
  1. (Background) [A Primer in BERTology: What We Know About How BERT Works](https://aclanthology.org/2020.tacl-1.54/)

Apr. 28, Thu
: Future Prediction, Causality ([Reading Survey](https://forms.gle/Hkraa4byC4tSSsno8) / [Slides](https://docs.google.com/presentation/d/14CQdqYG2JxndW4a0A0tprG2XJgE85KWDthHkT5Fetao/edit?usp=sharing))
  : Alexander, Heejun, Peisen, Tiancheng
: 1. [Attention over learned object embeddings enables complex visual reasoning](https://arxiv.org/abs/2012.08508)
  1. [PHYRE: A New Benchmark for Physical Reasoning](https://arxiv.org/abs/1908.05656)
  1. (Background) [Machine Theory of Mind](https://arxiv.org/abs/1802.07740)
  1. (Background) [Shaking the foundations: delusions in sequence models for interaction and control](https://arxiv.org/abs/2110.10819)

Apr. 29, Fri
: **Due**{: .label .label-purple} [Presentation Slot Signup](https://forms.gle/J8KYBpEXkHA9xbJ98)

May 3, Tue
: _Final project office hours_

May 5, Thu
: _Final project office hours_

May 10, Tue
: Final project presentations ([Slides](https://docs.google.com/presentation/d/1DlnYw_fRSvEut7mW4-Ji-d8x-jnHvfgTyrUfBVrTehw/edit?usp=sharing))

May 12, Thu
: Final project presentations ([Slides](https://docs.google.com/presentation/d/1DlnYw_fRSvEut7mW4-Ji-d8x-jnHvfgTyrUfBVrTehw/edit?usp=sharing))

May 13, Fri
: **Due**{: .label .label-purple} [Project submission](https://forms.gle/XQpcArtdC8WKFVq97)

May 22, Fri
: **Due**{: .label .label-purple} [Post-semester feedback](https://forms.gle/DtE4AtZoN9nT4Xfe7)

Other
: Student Nominated Readings
: 1. (Physics-informed ML) [Physics-informed neural networks](https://www.sciencedirect.com/science/article/pii/S0021999118307125)
  1. (Operator Learning) [Learning nonlinear operators via DeepONet](https://www.nature.com/articles/s42256-021-00302-5)
  1. (Biologically-Inspired Learning) [Training Spiking Neural Networks Using Lessons From Deep Learning](https://arxiv.org/abs/2109.12894)