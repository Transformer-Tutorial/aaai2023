---
title: Paper reading list and presenters
---

Session 1
: Introduction and Motivation (May 24, 19:00 - 19:50)
  : Boqing Gong, Chen Sun

Session 2
: Recurrent Networks, Attention, Transformers (May 24, 20:00 - 21:30)
  : Boqing Gong, Chen Sun
: 1. [The Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)
  1. [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
  1. [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)

Session 3
: Transformers for Vision and Long Sequences (May 24, 21:30 - 23:00)
  : Boqing Gong, Chen Sun
: 1. [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
  1. [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)
  1. [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062)
  1. [Long Range Arena: A Benchmark for Efficient Transformers](https://arxiv.org/abs/2011.04006)

Session 4
: Optimization for Transformers (May 25, 19:00 - 19:50)
  : Boqing Gong
: 1. [When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations](https://arxiv.org/abs/2106.01548)
  1. [Surrogate Gap Minimization Improves Sharpness-Aware Training](https://openreview.net/forum?id=edONMAnhLu-)

Session 5
: Self-supervised Transformers (May 25, 20:00 - 20:50)
  : Chen Sun
: 1. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
  1. [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)

Session 6
: Multimodal Transformers (May 26, 19:00 - 20:50)
  : Boqing Gong, Chen Sun
: 1. [Attention Bottlenecks for Multimodal Fusion](https://arxiv.org/abs/2107.00135)
  1. [VideoBERT: A Joint Model for Video and Language Representation Learning](https://arxiv.org/abs/1904.01766)
  1. [VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text](https://arxiv.org/abs/2104.11178)
  1. [CLIP: Connecting Text and Images](https://openai.com/blog/clip/)

Session 7
: Model Interpretability (May 26, 21:00 - 21:50)
  : Chen Sun
: 1. [A Primer in BERTology: What we know about how BERT works](https://arxiv.org/abs/2002.12327)
  1. [BERT Rediscovers the Classical NLP Pipeline](https://arxiv.org/abs/1905.05950)
  1. [Do Vision-Language Pretrained Models Learn Primitive Concepts?](https://arxiv.org/abs/2203.17271)

Session 8
: Advanced Topics, Recap (May 26, 22:00 - 22:50)
  : Boqing Gong