---
title: Lecture slides
---

1
: The Transformer Architecture and its Variants
  : [Neil Houlsby](https://neilhoulsby.github.io/)
: [Slides]()

2
: How to Train Your (Vision) Transformer?
  : [Boqing Gong](http://boqinggong.info/)
: [Slides](https://docs.google.com/presentation/d/1thqJUT_JpYEd5me1tlO3Xx1stu6LP8O69FYZ0mIoXlE/edit?usp=sharing&resourcekey=0-9RpTY2S2yQvRajK2c0lR_g)

3
: Does Multimodal Pretraining Learn Useful Representation for Reasoning?
  : [Chen Sun](https://chensun.me)
: [Slides](https://drive.google.com/file/d/1BWzHt1c3NPx5x0EhplnyiWBT364myO4q/view?usp=share_link)

4
: Language as Robot Middleware
  : [Andy Zeng](https://andyzeng.github.io/)
: [Slides](https://slides.com/andyzeng/2023-aaai-tutorial)

5
: Probing Knowledge and Structure in Transformers
  : [Ellie Pavlick](https://cs.brown.edu/people/epavlick/)
: [Slides](https://drive.google.com/file/d/1yovyfHRzM5lE8-7HPGefmmEDkpepB7Sj/view?usp=sharing)
